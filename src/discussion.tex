\section{Conclusion and Discussion} \label{sec:discussion}

In this paper, we discussed how to build a network solution for containers,
named \sysname. It offers high performance, good portability and acceptable
isolation. We sketched the design of \sysname which enables containers to
communicate with the most efficient way according to their locations and
hardware capabilities and keeps the decisions transparent to applications in
containers. We are currently building \sysname, and we list a few important
considerations below.

\textbf{Live migration:} 
\sysname could be a key enabler
for containers to achieve both high-performance and capability for live
migration. It will require the network library to interact with the orchestrator
more frequently, and may require maintaining additional per-connection state
within the library. We are currently investigating this further.

\textbf{Security and middle-box:} One valid concern for \sysname is how legacy
middle-boxes will work for communication via shared-memory or RDMA, and whether
security will be broken by using shared-memory or RDMA.  We do not yet have
complete answer to this issue. We envision that for security, \sysname would
only allow shared-memory among trusted containers, for example, container
belongs to the same vendor (e.g., running spark or storm).  We are investigating
how best to support existing middle-boxes (e.g. IDS/IPS) under \sysname.


\textbf{VM environment:}
So far our evaluation and prototype is based on containers running on
bare-metal.  But our design easily generalizes to containers deployed inside
VMs. Some issues, such as efficient inter-VM communication (perhaps using
NetVM~\cite{netvm}) need to be addressed, but we believe that it can be easily
done within the context of \sysname design.


\textbf{Scalability of \sysname :}
Scalability of \sysname is a major focus of our ongoing work. The design proposed
in \S\ref{sec:design} has a few potential scalability challenges. For example,
if overlay routers in \sysname may end up having to maintain per-flow state if
they communicate with co-located containers using shared memory and with remote
routers using RDMA -- if done n\"{a}ively, the router may end up maintaining
one queue pair for each pair of communicating containers.  To solve this
problem, we need to to multiplex a single queue pair on overlay routers for
multiple container sessions.


%\textbf{Network trouble shooting:}

%\textbf{VM environment:}
%So far our evaluation and prototype is based on containers running on bare-metal. 
%Although we believe our design is also general for containers deployed inside VMs,
%the VM environment can brought in further challenges such as how to handle the
%address mapping, how to enable shared-memory/RDMA or how to locate the containers
%and measure the utility of resources. We will address these challenges in our futureworks.
