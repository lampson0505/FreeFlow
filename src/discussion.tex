\section{Conclusion and Discussions} \label{sec:discussion}

In this paper, we discuss how to build a network solution for containers, named \sysname, 
which has high performance, good portability and acceptable isolation. We sketch
the design of \sysname which enables containers to communicate with the most efficient
way according to their locations and hardware capabilities and keeps the decisions
transparent to applications in containers. We are currently building \sysname, and
we list several important considerations we are investigating at present in the following.

\textbf{Live migration:} 
\sysname could be a key enabler
for containers to achieve both high-performance and capability for live
migration. It will require the network library to interact with the orchestrator
more frequently, and may require maintaining additional per-connection state
within the library. We are currently investigating this further.

\textbf{Security and middle-box:} One valid concern for \sysname is how legacy
middle-boxes will work for communication via shared-memory or RDMA, and whether
security will be broken by using shared-memory or RDMA.  We do not yet have
complete answer to this issue. We envision that for security, \sysname would
only allow shared-memory among trusted containers, for example, container
belongs to the same vendor (e.g., running spark or storm).  We are investigating
how best to support existing middle-boxes (e.g. IDS/IPS) under \sysname.


\textbf{VM environment:}
So far our evaluation and prototype is based on containers running on
bare-metal.  But our design easily generalizes to containers deployed inside
VMs. Some issues, such as efficient inter-VM communication (perhaps using
NetVM~\cite{netvm}) need to be addressed, but we believe that it can be easily
done within the context of \sysname design.


\textbf{Scalability of \sysname :}
There is a potential scalability issue in the current design of overlay router in \sysname.
Suppose overlay routers are using RDMA to transfer inter-host data, one overlay router 
will maintain one RDMA queue pair for each pair of containers, if one of containers is on 
the same host as the overlay router. Therefore, the number of queue pairs one overlay router
maintains can be up to $O(m \times N)$, if $m$ is the number of containers on the same host
and $N$ is the number of containers in other hosts. To solve this problem, we need to consider
how to multiplex a single queue pair on overlay routers for multiple container sessions 
in the future work. 


%\textbf{Network trouble shooting:}

%\textbf{VM environment:}
%So far our evaluation and prototype is based on containers running on bare-metal. 
%Although we believe our design is also general for containers deployed inside VMs,
%the VM environment can brought in further challenges such as how to handle the
%address mapping, how to enable shared-memory/RDMA or how to locate the containers
%and measure the utility of resources. We will address these challenges in our futureworks.
